import streamlit as st
import os
from workflow import parse_pdf, process_document, answer_question, get_model
import logging
import traceback
import lancedb
import pyarrow as pa
import re
from indexify.functions_sdk.graph import Graph

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ç¡®ä¿æ¨¡å‹åœ¨åº”ç”¨å¯åŠ¨æ—¶å°±åŠ è½½
get_model()

# å°† display_chunk å‡½æ•°ç§»åˆ°è¿™é‡Œ
def display_chunk(chunk_id, chunk_content):
    with st.expander(f"æ–‡æœ¬å— {chunk_id}"):
        st.text_area("å†…å®¹", chunk_content, height=100, key=f"chunk_{chunk_id}")

# æ·»åŠ  submit_question å‡½æ•°
def submit_question():
    st.session_state.submit_question = True

st.set_page_config(page_title="æ–‡æ¡£é—®ç­”ç³»ç»Ÿ", page_icon="ğŸ“š", layout="wide")

st.title("æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")

# ç¡®ä¿ data ç›®å½•å­˜åœ¨
if not os.path.exists("data"):
    os.makedirs("data")

# æ·»åŠ ä¸€ä¸ªå‡½æ•°æ¥å¤„ç† data ç›®å½•ä¸‹çš„æ‰€æœ‰ PDF æ–‡ä»¶
def process_all_pdfs():
    pdf_files = [f for f in os.listdir("data") if f.endswith(".pdf")]
    for pdf_file in pdf_files:
        file_path = os.path.join("data", pdf_file)
        try:
            with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {pdf_file}"):
                st.text(f"å¼€å§‹è§£æ PDF æ–‡ä»¶: {pdf_file}")
                doc = parse_pdf(file_path)
                st.text(f"PDF è§£æå®Œæˆï¼Œå¼€å§‹å¤„ç†æ–‡æ¡£å†…å®¹")
                process_document(doc, pdf_file)
            st.success(f"æ–‡æ¡£ {pdf_file} å¤„ç†å®Œæˆ!")
        except Exception as e:
            st.error(f"å¤„ç†æ–‡æ¡£ {pdf_file} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            logging.error(f"å¤„ç†æ–‡æ¡£ {pdf_file} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            logging.error(traceback.format_exc())

# æ·»åŠ ä¸€ä¸ªæŒ‰é’®æ¥å¤„ç†æ‰€æœ‰ PDF æ–‡ä»¶
if st.button("å¤„ç† data ç›®å½•ä¸‹çš„æ‰€æœ‰ PDF æ–‡æ¡£"):
    process_all_pdfs()

# æ–‡æ¡£ä¸Šä¼ éƒ¨åˆ†ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
uploaded_file = st.file_uploader("ä¸Šä¼ æ–°çš„PDFæ–‡æ¡£", type="pdf")

if uploaded_file is not None:
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ° data ç›®å½•
        file_path = os.path.join("data", uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(f"æ–‡æ¡£å·²ä¸Šä¼ å¹¶ä¿å­˜ä¸º: {file_path}")
        
        if st.button("å¤„ç†æ–°ä¸Šä¼ çš„æ–‡æ¡£"):
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                doc = parse_pdf(file_path)
                process_document(doc, uploaded_file.name)
            st.success("æ–‡æ¡£å¤„ç†å®Œæˆ!")
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        logging.error(f"å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        logging.error(traceback.format_exc())

# ç­”éƒ¨åˆ†
st.subheader("æ–‡æ¡£é—®ç­”")

# ä¿®æ”¹é—®é¢˜è¾“å…¥æ¡†ï¼Œæ·»åŠ  on_change å‚æ•°
question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ (æŒ‰å›è½¦æäº¤):", key="question_input", on_change=submit_question)

# æ£€æŸ¥æ˜¯å¦åº”è¯¥æäº¤é—®é¢˜
if 'submit_question' not in st.session_state:
    st.session_state.submit_question = False

if st.session_state.submit_question and question:
    try:
        with st.spinner("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ..."):
            rag_response, contextual_response = answer_question(question)
        
        st.subheader("RAG è¾“å‡º:")
        st.markdown(f"**{rag_response['patient_name']}**")
        st.markdown(f"**{rag_response['answer']}**")
        st.markdown(f"**{rag_response['explanation']}**")
        st.markdown(f"**{rag_response['confidence']}**")
        
        # åˆ›å»ºä¸€ä¸ªå¯å±•å¼€çš„éƒ¨åˆ†æ¥æ˜¾ç¤ºå¼•ç”¨
        with st.expander("å¼•ç”¨"):
            for citation in rag_response['citations']:
                st.write(f"Chunk ID: {citation['chunk_id']}")
                st.write(citation['content'])
                st.write("---")

        st.subheader("ä¸Šä¸‹æ–‡æ„ŸçŸ¥ RAG è¾“å‡º:")
        st.markdown(f"**{contextual_response['patient_name']}**")
        st.markdown(f"**{contextual_response['answer']}**")
        st.markdown(f"**{contextual_response['explanation']}**")
        st.markdown(f"**{contextual_response['confidence']}**")
        
        # åˆ›å»ºä¸€ä¸ªå¯å±•å¼€çš„éƒ¨åˆ†æ¥æ˜¾ç¤ºä¸Šä¸‹æ–‡æ„ŸçŸ¥å¼•ç”¨
        with st.expander("ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¼•ç”¨"):
            for citation in contextual_response['citations']:
                st.write(f"Chunk ID: {citation['chunk_id']}")
                st.write("Content:")
                st.write(citation['content'])
                st.write("Context:")
                st.write(citation['context'])
                st.write("---")

        # é‡ç½®æäº¤çŠ¶æ€
        st.session_state.submit_question = False
    except Exception as e:
        st.error(f"å›ç­”é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        logging.error(f"å›ç­”é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        logging.error(traceback.format_exc())
elif st.session_state.submit_question and not question:
    st.warning("è¯·è¾“å…¥ä¸€ä¸ªé—®é¢˜ã€‚")
    st.session_state.submit_question = False

st.sidebar.header("ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. å¦‚æœéœ€è¦æ·»åŠ æ–°æ–‡æ¡£ï¼Œè¯·ä¸Šä¼ PDFæ–‡æ¡£å¹¶ç‚¹å‡»"å¤„ç†æ–‡æ¡£"æŒ‰é’®
2. ç›´æ¥åœ¨é—®é¢˜è¾“å…¥æ¡†ä¸­è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦é”®æäº¤
3. æŸ¥çœ‹ç”Ÿæˆçš„ç­”æ¡ˆ
4. æ‚¨å¯ä»¥ç»§ç»­æé—®ï¼Œæ— éœ€æ¯æ¬¡éƒ½ä¸Šä¼ æ–‡æ¡£
""")

def validate_lancedb_data():
    l_client = lancedb.connect("vectordb.lance")
    chunks = l_client.open_table("chunk-embeddings").to_arrow()
    for i, chunk in enumerate(chunks):
        patient_name = extract_patient_name(chunk['chunk'].as_py())
        print(f"Chunk {i}: Patient: {patient_name}, Content: {chunk['chunk'].as_py()[:100]}...")  # æ‰“å°å‰100ä¸ªå­—ç¬¦

def process_document(doc, file_name):
    g: Graph = Graph("test", start_node=generate_chunk_contexts)
    g.add_edge(generate_chunk_contexts, TextEmbeddingExtractor)
    g.add_edge(TextEmbeddingExtractor, LanceDBWriter)
    g.run(block_until_done=True, doc=doc, file_name=file_name)
